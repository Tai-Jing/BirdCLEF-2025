{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab7b605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:02:59.998288Z",
     "iopub.status.busy": "2025-05-28T15:02:59.997948Z",
     "iopub.status.idle": "2025-05-28T15:03:19.450038Z",
     "shell.execute_reply": "2025-05-28T15:03:19.448313Z"
    },
    "papermill": {
     "duration": 19.460002,
     "end_time": "2025-05-28T15:03:19.452929",
     "exception": false,
     "start_time": "2025-05-28T15:02:59.992927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: ../input/openvino-wheels\r\n",
      "Processing /kaggle/input/openvino-wheels/openvino_dev-2024.6.0-17404-py3-none-any.whl (from openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1))\r\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (0.7.1)\r\n",
      "Processing /kaggle/input/openvino-wheels/networkx-3.1-py3-none-any.whl (from openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1))\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.6 in /usr/local/lib/python3.11/dist-packages (from openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (1.26.4)\r\n",
      "Processing /kaggle/input/openvino-wheels/openvino_telemetry-2025.1.0-py3-none-any.whl (from openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1))\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.11/dist-packages (from openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (6.0.2)\r\n",
      "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.11/dist-packages (from openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (2.32.3)\r\n",
      "Processing /kaggle/input/openvino-wheels/openvino-2024.6.0-17404-cp311-cp311-manylinux2014_x86_64.whl (from openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1))\r\n",
      "Processing /kaggle/input/openvino-wheels/fastjsonschema-2.17.1-py3-none-any.whl (from openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1))\r\n",
      "Requirement already satisfied: onnx<=1.17.0,>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (1.17.0)\r\n",
      "Requirement already satisfied: protobuf<4.0.0,>=3.18.1 in /usr/local/lib/python3.11/dist-packages (from openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (3.20.3)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.16.6->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.16.6->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.16.6->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.16.6->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.16.6->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0.0,>=1.16.6->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.1->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.1->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.1->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.25.1->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (2025.4.26)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.16.6->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0.0,>=1.16.6->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.16.6->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0.0,>=1.16.6->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0.0,>=1.16.6->openvino-dev==2024.6.0->openvino-dev[onnx]==2024.6.0->-r ../input/openvino-wheels/requirements.txt (line 1)) (2024.2.0)\r\n",
      "Installing collected packages: openvino-telemetry, fastjsonschema, networkx, openvino, openvino-dev\r\n",
      "  Attempting uninstall: fastjsonschema\r\n",
      "    Found existing installation: fastjsonschema 2.21.1\r\n",
      "    Uninstalling fastjsonschema-2.21.1:\r\n",
      "      Successfully uninstalled fastjsonschema-2.21.1\r\n",
      "  Attempting uninstall: networkx\r\n",
      "    Found existing installation: networkx 3.4.2\r\n",
      "    Uninstalling networkx-3.4.2:\r\n",
      "      Successfully uninstalled networkx-3.4.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "nx-cugraph-cu12 25.2.0 requires networkx>=3.2, but you have networkx 3.1 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.9.0.13 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.4.0.6 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.10.19 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.4.40 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.9.5 which is incompatible.\r\n",
      "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.9.41 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed fastjsonschema-2.17.1 networkx-3.1 openvino-2024.6.0 openvino-dev-2024.6.0 openvino-telemetry-2025.1.0\r\n",
      "Collecting onnxsim\r\n",
      "  Downloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\r\n",
      "Requirement already satisfied: onnx in /usr/local/lib/python3.11/dist-packages (from onnxsim) (1.17.0)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from onnxsim) (14.0.0)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxsim) (1.26.4)\r\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from onnx->onnxsim) (3.20.3)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->onnxsim) (2.19.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->onnxsim) (0.1.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->onnx->onnxsim) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->onnx->onnxsim) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->onnx->onnxsim) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->onnx->onnxsim) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->onnx->onnxsim) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.20->onnx->onnxsim) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->onnx->onnxsim) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.20->onnx->onnxsim) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->onnx->onnxsim) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.20->onnx->onnxsim) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.20->onnx->onnxsim) (2024.2.0)\r\n",
      "Downloading onnxsim-0.4.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: onnxsim\r\n",
      "Successfully installed onnxsim-0.4.36\r\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install --no-index --find-links=../input/openvino-wheels -r ../input/openvino-wheels/requirements.txt\n",
    "!pip install onnxsim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f82acc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:03:19.465071Z",
     "iopub.status.busy": "2025-05-28T15:03:19.464706Z",
     "iopub.status.idle": "2025-05-28T15:03:54.050052Z",
     "shell.execute_reply": "2025-05-28T15:03:54.048578Z"
    },
    "papermill": {
     "duration": 34.594191,
     "end_time": "2025-05-28T15:03:54.052829",
     "exception": false,
     "start_time": "2025-05-28T15:03:19.458638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Installing onnxruntime by `/usr/bin/python3 -m pip install onnxruntime`, please wait for a moment..</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mInstalling onnxruntime by `/usr/bin/python3 -m pip install onnxruntime`, please wait for a moment..\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->onnxruntime) (2.4.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.6->onnxruntime) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.6->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.6->onnxruntime) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.6->onnxruntime) (2024.2.0)\n",
      "Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.4/16.4 MB 76.2 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.22.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "import logging\n",
    "import time\n",
    "import math\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from soundfile import SoundFile \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import timm\n",
    "from tqdm.auto import tqdm\n",
    "from glob import glob\n",
    "import torchaudio\n",
    "import random\n",
    "import itertools\n",
    "from typing import Union\n",
    "\n",
    "import pickle\n",
    "import torchaudio\n",
    "import torchaudio.transforms as AT\n",
    "from contextlib import contextmanager\n",
    "import concurrent.futures\n",
    "\n",
    "import onnx # 用于加载和保存 ONNX 模型\n",
    "import onnxsim # 用于简化 ONNX 模型\n",
    "from openvino.tools import mo # 用于模型转换\n",
    "import openvino as ov\n",
    "from openvino.runtime import Core # 用于模型加载和推理\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e587cc04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:03:54.065240Z",
     "iopub.status.busy": "2025-05-28T15:03:54.064257Z",
     "iopub.status.idle": "2025-05-28T15:03:54.100303Z",
     "shell.execute_reply": "2025-05-28T15:03:54.098650Z"
    },
    "papermill": {
     "duration": 0.0448,
     "end_time": "2025-05-28T15:03:54.102771",
     "exception": false,
     "start_time": "2025-05-28T15:03:54.057971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading taxonomy data...\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    " \n",
    "    taxonomy_csv = '/kaggle/input/birdclef-2025/taxonomy.csv'\n",
    "\n",
    "    model_dicts = {\n",
    "    \"eca_nfnet_l0\":['/kaggle/input/birdclef-2025-sed-models-p/sed0.pth',\n",
    "                    '/kaggle/input/birdclef-2025-sed-models-p/sed1.pth',\n",
    "                    '/kaggle/input/birdclef-2025-sed-models-p/sed2.pth']\n",
    "  \n",
    "}\n",
    "\n",
    "    num_classes = 206\n",
    "    n_mels=128\n",
    "    in_channels = 3\n",
    "    device = 'cpu'  \n",
    "    pretrained=False\n",
    "    # Inference parameters\n",
    "    batch_size = 32  \n",
    "    # TTA 的次数。 如果 use_tta 为 True，则指定对每个测试样本进行多少次增强。\n",
    "    threshold = 0.5\n",
    "\n",
    "    debug =  True\n",
    "    # True  False\n",
    "    debug_count = 3\n",
    "\n",
    "cfg = CFG()\n",
    "print(f\"Using device: {cfg.device}\")\n",
    "print(f\"Loading taxonomy data...\")\n",
    "taxonomy_df = pd.read_csv(cfg.taxonomy_csv)\n",
    "species_ids = taxonomy_df['primary_label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "366c67dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:03:54.116637Z",
     "iopub.status.busy": "2025-05-28T15:03:54.115794Z",
     "iopub.status.idle": "2025-05-28T15:03:54.139361Z",
     "shell.execute_reply": "2025-05-28T15:03:54.138226Z"
    },
    "papermill": {
     "duration": 0.032847,
     "end_time": "2025-05-28T15:03:54.141304",
     "exception": false,
     "start_time": "2025-05-28T15:03:54.108457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    "    if hasattr(layer, \"bias\"):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "def init_bn(bn):\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.0)\n",
    "\n",
    "\n",
    "def init_weights(model):\n",
    "    classname = model.__class__.__name__\n",
    "    if classname.find(\"Conv2d\") != -1:\n",
    "        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        model.weight.data.normal_(1.0, 0.02)\n",
    "        model.bias.data.fill_(0)\n",
    "    elif classname.find(\"GRU\") != -1:\n",
    "        for weight in model.parameters():\n",
    "            if len(weight.size()) > 1:\n",
    "                nn.init.orghogonal_(weight.data)\n",
    "    elif classname.find(\"Linear\") != -1:\n",
    "        model.weight.data.normal_(0, 0.01)\n",
    "        model.bias.data.zero_()\n",
    "\n",
    "\n",
    "def interpolate(x, ratio):\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output, frames_num):\n",
    "    output = F.interpolate(\n",
    "        framewise_output.unsqueeze(1),\n",
    "        size=(frames_num, framewise_output.size(2)),\n",
    "        align_corners=True,\n",
    "        mode=\"bilinear\").squeeze(1)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "class AttBlockV2(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class TimmSED(nn.Module):\n",
    "    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1, n_mels=24):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(n_mels)\n",
    "\n",
    "        base_model = timm.create_model(\n",
    "            base_model_name, pretrained=pretrained, in_chans=in_channels)\n",
    "        layers = list(base_model.children())[:-2]\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "\n",
    "        in_features = base_model.num_features\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n",
    "        self.att_block2 = AttBlockV2(\n",
    "            in_features, num_classes, activation=\"sigmoid\")\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_data):\n",
    "        x = input_data.transpose(2,3)\n",
    "        x = torch.cat((x,x,x),1)\n",
    "\n",
    "        x = x.transpose(2, 3)\n",
    "\n",
    "        x = self.encoder(x)\n",
    "        \n",
    "        x = torch.mean(x, dim=2)\n",
    "\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block2(x)\n",
    "        logit = torch.sum(norm_att * self.att_block2.cla(x), dim=2)\n",
    "\n",
    "\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1a7bc3",
   "metadata": {
    "papermill": {
     "duration": 0.005704,
     "end_time": "2025-05-28T15:03:54.152211",
     "exception": false,
     "start_time": "2025-05-28T15:03:54.146507",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "386c6ef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:03:54.165780Z",
     "iopub.status.busy": "2025-05-28T15:03:54.165396Z",
     "iopub.status.idle": "2025-05-28T15:03:54.178353Z",
     "shell.execute_reply": "2025-05-28T15:03:54.177107Z"
    },
    "papermill": {
     "duration": 0.021616,
     "end_time": "2025-05-28T15:03:54.180077",
     "exception": false,
     "start_time": "2025-05-28T15:03:54.158461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_pytorch_to_openvino(pytorch_model, model_name, output_dir, example_input_shape,i):\n",
    "    \"\"\"\n",
    "    将 PyTorch 模型转换为 OpenVINO IR (Intermediate Representation) 格式，\n",
    "    并使用 ONNX Simplifier 进行优化。\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 原始 ONNX 模型的路径 (由 PyTorch 导出)\n",
    "    onnx_original_path = os.path.join(output_dir, f\"{model_name}_{i}_original.onnx\")\n",
    "    # 简化后的 ONNX 模型的路径 (由 ONNX Simplifier 处理后)\n",
    "    onnx_simplified_path = os.path.join(output_dir, f\"{model_name}_{i}_simplified.onnx\")\n",
    "    # OpenVINO IR 模型的 XML 文件路径\n",
    "    xml_path = os.path.join(output_dir, f\"{model_name}_{i}.xml\")\n",
    "    \n",
    "    # 1. 将 PyTorch 模型设置为评估模式并移动到 CPU\n",
    "    pytorch_model.eval()\n",
    "    pytorch_model.cpu() # 将模型移动到 CPU 进行导出，通常更稳定\n",
    "    \n",
    "    print(f\"--- 阶段 1/3: 将 PyTorch 模型 '{model_name}' 导出为 ONNX ---\")\n",
    "    dummy_input = torch.randn(example_input_shape)\n",
    "    \n",
    "    try:\n",
    "        torch.onnx.export(pytorch_model, \n",
    "                          dummy_input, # 虚拟输入\n",
    "                          onnx_original_path,\n",
    "                          verbose=False, # 设置为 True 可以看到更详细的导出过程\n",
    "                          opset_version=13, # 推荐使用 13 或更高版本\n",
    "                          input_names=['input0'],\n",
    "                          output_names=['output0'],\n",
    "                          # dynamic_axes 的设置需要与你的实际模型需求匹配\n",
    "                          # 如果你的模型可以处理动态 batch_size，可以保留这一行\n",
    "                          # 如果你的模型的时间步长也可以动态，可以加上 'time_steps'\n",
    "                          dynamic_axes={'input_audio': {0: 'batch_size'}} \n",
    "                         )\n",
    "        print(f\"原始 ONNX 模型已保存到: {onnx_original_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"导出 ONNX 失败: {e}\")\n",
    "        return None\n",
    "\n",
    "    # 2. 使用 ONNX Simplifier 优化 ONNX 模型\n",
    "    if os.path.exists(onnx_original_path):\n",
    "        print(f\"--- 阶段 2/3: 使用 ONNX Simplifier 优化 ONNX 模型 ---\")\n",
    "        try:\n",
    "            # onnxsim.simplify 可以直接接受文件路径\n",
    "            simplified_model, check_ok = onnxsim.simplify(onnx_original_path)\n",
    "\n",
    "            if check_ok:\n",
    "                onnx.save(simplified_model, onnx_simplified_path)\n",
    "                print(f\"ONNX 模型已简化并保存到: {onnx_simplified_path}\")\n",
    "            else:\n",
    "                print(\"警告: ONNX Simplifier 报告简化过程中存在问题，但仍将尝试使用简化后的模型进行转换。\")\n",
    "                onnx.save(simplified_model, onnx_simplified_path) # 即使有警告也尝试保存和使用\n",
    "        except Exception as e:\n",
    "            print(f\"ONNX Simplifier 失败: {e}\")\n",
    "            print(f\"注意: 无法简化 ONNX 模型，尝试使用原始 ONNX 进行 OpenVINO 转换（可能失败）。\")\n",
    "            # 如果简化失败，可以选择直接返回 None，或者尝试使用原始 ONNX (不推荐，因为原始的就报错)\n",
    "            # 这里我们选择直接返回 None，因为简化是解决 BN 问题的关键\n",
    "            return None\n",
    "    else:\n",
    "        print(\"原始 ONNX 文件不存在，无法进行简化。\")\n",
    "        return None\n",
    "\n",
    "    # 3. 使用 OpenVINO Model Optimizer 将简化的 ONNX 模型转换为 OpenVINO IR\n",
    "    print(f\"--- 阶段 3/3: 使用 OpenVINO Model Optimizer 将简化的 ONNX 模型转换为 OpenVINO IR ---\")\n",
    "    try:\n",
    "        # 使用简化的 ONNX 模型进行转换\n",
    "        ov_model = ov.convert_model(onnx_simplified_path) \n",
    "        # 保存为 FP16 可以减小模型大小并提高推理速度\n",
    "        ov.save_model(ov_model, xml_path, compress_to_fp16=True) \n",
    "        print(f\"OpenVINO IR 模型已保存到: {xml_path} 和 {Path(xml_path).with_suffix('.bin')}\")\n",
    "        return xml_path\n",
    "    except Exception as e:\n",
    "        print(f\"转换为 OpenVINO IR 失败: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e01a2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:03:54.191484Z",
     "iopub.status.busy": "2025-05-28T15:03:54.191185Z",
     "iopub.status.idle": "2025-05-28T15:03:54.197895Z",
     "shell.execute_reply": "2025-05-28T15:03:54.196442Z"
    },
    "papermill": {
     "duration": 0.014636,
     "end_time": "2025-05-28T15:03:54.199763",
     "exception": false,
     "start_time": "2025-05-28T15:03:54.185127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_openvino_model(xml_path, device=\"CPU\"):\n",
    "    \"\"\"\n",
    "    加载 OpenVINO IR 模型并编译。\n",
    "\n",
    "    Args:\n",
    "        xml_path (str): OpenVINO IR 模型的 .xml 文件路径。\n",
    "        device (str): 推理设备\n",
    "    Returns:\n",
    "        openvino.runtime.CompiledModel: 编译后的 OpenVINO 模型对象。\n",
    "    \"\"\"\n",
    "    core = Core()\n",
    "    model = core.read_model(model=xml_path)\n",
    "    \n",
    "    # 编译模型以优化到指定设备\n",
    "    compiled_model = core.compile_model(model=model, device_name=device)\n",
    "    print(f\"OpenVINO 模型 '{Path(xml_path).stem}' 已编译到设备: {device}\")\n",
    "    return compiled_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b07e861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-28T15:03:54.211926Z",
     "iopub.status.busy": "2025-05-28T15:03:54.211622Z",
     "iopub.status.idle": "2025-05-28T15:05:08.665995Z",
     "shell.execute_reply": "2025-05-28T15:05:08.663976Z"
    },
    "papermill": {
     "duration": 74.463914,
     "end_time": "2025-05-28T15:05:08.668970",
     "exception": false,
     "start_time": "2025-05-28T15:03:54.205056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 阶段 1/3: 将 PyTorch 模型 'eca_nfnet_l0' 导出为 ONNX ---\n",
      "原始 ONNX 模型已保存到: /kaggle/working/model_0/eca_nfnet_l0_0_original.onnx\n",
      "--- 阶段 2/3: 使用 ONNX Simplifier 优化 ONNX 模型 ---\n",
      "ONNX 模型已简化并保存到: /kaggle/working/model_0/eca_nfnet_l0_0_simplified.onnx\n",
      "--- 阶段 3/3: 使用 OpenVINO Model Optimizer 将简化的 ONNX 模型转换为 OpenVINO IR ---\n",
      "OpenVINO IR 模型已保存到: /kaggle/working/model_0/eca_nfnet_l0_0.xml 和 /kaggle/working/model_0/eca_nfnet_l0_0.bin\n",
      "模型转换成功，IR路径: /kaggle/working/model_0/eca_nfnet_l0_0.xml\n",
      "OpenVINO 模型 'eca_nfnet_l0_0' 已编译到设备: CPU\n",
      "(12, 1, 128, 313)\n",
      "(12, 206)\n",
      "...............................\n",
      "--- 阶段 1/3: 将 PyTorch 模型 'eca_nfnet_l0' 导出为 ONNX ---\n",
      "原始 ONNX 模型已保存到: /kaggle/working/model_1/eca_nfnet_l0_1_original.onnx\n",
      "--- 阶段 2/3: 使用 ONNX Simplifier 优化 ONNX 模型 ---\n",
      "ONNX 模型已简化并保存到: /kaggle/working/model_1/eca_nfnet_l0_1_simplified.onnx\n",
      "--- 阶段 3/3: 使用 OpenVINO Model Optimizer 将简化的 ONNX 模型转换为 OpenVINO IR ---\n",
      "OpenVINO IR 模型已保存到: /kaggle/working/model_1/eca_nfnet_l0_1.xml 和 /kaggle/working/model_1/eca_nfnet_l0_1.bin\n",
      "模型转换成功，IR路径: /kaggle/working/model_1/eca_nfnet_l0_1.xml\n",
      "OpenVINO 模型 'eca_nfnet_l0_1' 已编译到设备: CPU\n",
      "(12, 1, 128, 313)\n",
      "(12, 206)\n",
      "...............................\n",
      "--- 阶段 1/3: 将 PyTorch 模型 'eca_nfnet_l0' 导出为 ONNX ---\n",
      "原始 ONNX 模型已保存到: /kaggle/working/model_2/eca_nfnet_l0_2_original.onnx\n",
      "--- 阶段 2/3: 使用 ONNX Simplifier 优化 ONNX 模型 ---\n",
      "ONNX 模型已简化并保存到: /kaggle/working/model_2/eca_nfnet_l0_2_simplified.onnx\n",
      "--- 阶段 3/3: 使用 OpenVINO Model Optimizer 将简化的 ONNX 模型转换为 OpenVINO IR ---\n",
      "OpenVINO IR 模型已保存到: /kaggle/working/model_2/eca_nfnet_l0_2.xml 和 /kaggle/working/model_2/eca_nfnet_l0_2.bin\n",
      "模型转换成功，IR路径: /kaggle/working/model_2/eca_nfnet_l0_2.xml\n",
      "OpenVINO 模型 'eca_nfnet_l0_2' 已编译到设备: CPU\n",
      "(12, 1, 128, 313)\n",
      "(12, 206)\n",
      "...............................\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for model_name,model_paths in cfg.model_dicts.items():\n",
    "        for i,model_path in enumerate(model_paths):\n",
    "            \n",
    "            dummy_model = TimmSED(base_model_name = model_name,\n",
    "                                  pretrained=cfg.pretrained,\n",
    "                                  num_classes=cfg.num_classes,\n",
    "                                  in_channels=cfg.in_channels,\n",
    "                                  n_mels=cfg.n_mels )\n",
    "            dummy_model.load_state_dict(torch.load(model_path, \n",
    "                                                   map_location='cpu',\n",
    "                                                   weights_only = False)) # 加载训练好的权重\n",
    "            \n",
    "            output_ir_path = convert_pytorch_to_openvino(\n",
    "                dummy_model, \n",
    "                model_name, \n",
    "                output_dir=f\"/kaggle/working/model_{i}\", \n",
    "                example_input_shape=(12, 1, 128,313),\n",
    "                i=i)\n",
    "            if output_ir_path:\n",
    "                print(f\"模型转换成功，IR路径: {output_ir_path}\")\n",
    "            else:\n",
    "                print(\"模型转换失败。\")\n",
    "        \n",
    "            \n",
    "            model =  load_openvino_model(output_ir_path, device=\"CPU\")\n",
    "        \n",
    "            eginput = np.random.rand(*(12,1,128,313))\n",
    "            print(eginput.shape)\n",
    "            y = model(eginput)\n",
    "            # print(y.shape)\n",
    "            print(y['output0'].shape)\n",
    "            print(\"...............................\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3dad55",
   "metadata": {
    "papermill": {
     "duration": 0.011051,
     "end_time": "2025-05-28T15:05:08.691830",
     "exception": false,
     "start_time": "2025-05-28T15:05:08.680779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "datasetId": 7430593,
     "sourceId": 11828260,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7457365,
     "sourceId": 11867185,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7459455,
     "sourceId": 11870082,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7459522,
     "sourceId": 11870175,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7459867,
     "sourceId": 11870659,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7477284,
     "sourceId": 11895503,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7487257,
     "sourceId": 11909812,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 235777618,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 137.648427,
   "end_time": "2025-05-28T15:05:11.330094",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-28T15:02:53.681667",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
